% Talk for Valeev group on Jun 4

\documentclass[amsmath]{beamer}
\setbeamertemplate{navigation symbols}{} % Turn off navigation symbols
\usepackage{beamerthemeshadow}
\usepackage{dcolumn}               % Align table columns on decimal point
\usepackage{framed}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{multirow}
\usepackage{multicol}
\usepackage[export]{adjustbox}
\usepackage{biblatex}
\usepackage{pdfpages}
\bibliography{hci.bib}
\usefonttheme[onlymath]{serif}
\beamerdefaultoverlayspecification{<+->}

\newcommand\Wider[2][3em]{%
	\makebox[\linewidth][c]{%
		\begin{minipage}{\dimexpr\textwidth+#1\relax}
			\raggedright#2
		\end{minipage}%
	}%
}

\usecolortheme{orchid}

\AtBeginSection[]{
	\begin{frame}
		\vfill
		\centering
		\begin{beamercolorbox}[sep=8pt,center,shadow=true,rounded=true]{title}
			\usebeamerfont{frametitle}\insertsectionhead\par%
		\end{beamercolorbox}
		\vfill
	\end{frame}
}


\begin{document}
	\title[Semistochastic importance sampling]{Semistochastic importance sampling of second-quantized operators in determinant space}
	\author[A. Holmes]{Adam Holmes}
	\date{Valeev Group Meeting\\\today} 
	
	\frame{\titlepage} 
	
	\begin{frame}{Overview}
		\tableofcontents[hideallsubsections]
	\end{frame}

\section{Motivation}
\begin{frame}{Types of quantum chemistry algorithms}
	\begin{enumerate}
		\item Orbital-space algorithms:
		\begin{enumerate}
			\item Coupled cluster
			\item Moller-Plesset perturbation theory
			\linebreak
		\end{enumerate}
		\item Determinant-space algorithms:
		\begin{enumerate}
			\item Full CI
			\item Selected CI
			\item Epstein-Nesbet perturbation theory
			\item Full CI Quantum Monte Carlo (FCIQMC)
		\end{enumerate}
	\end{enumerate}
\end{frame}

%\begin{frame}{Determinant-space algorithms}
%	Slater determinants, second-quantized operators in this basis
%\end{frame}

\begin{frame}
	\small
	In determinant-space algorithms, one of the key steps is applying a second-quantized operator (usually $H$) to a Slater determinant!
	\begin{enumerate}
		\uncover<2->{\item Full CI: Iterative diagonalization of the Hamiltonian (e.g. using Davidson) diagonalizes in the basis of Krylov vectors \begin{eqnarray}\{v_i=f(Hv_{i-1})\}\end{eqnarray}}
		\uncover<3->{\item Selected CI: New determinants are `selected' using a criterion that is a function of $H\psi_0$}
		\uncover<4->{\item Epstein-Nesbet perturbation theory: \begin{eqnarray}\Delta E = \left\langle \psi_0 \left| V \frac{1}{E_0 - H_0} V \right|\psi_0\right\rangle\end{eqnarray}}
		\uncover<5->{\item FCIQMC: Stochastically simulate the power method, \begin{eqnarray}\psi_0 \propto \lim_{n\rightarrow\infty} (1 - \tau H)^n \psi_T\end{eqnarray}}
	\end{enumerate}
\end{frame}

\begin{frame}{Approaches for computing $H\left|D_i\right\rangle$}
	\small
	Broadly, there are three main approaches:
	\begin{enumerate}
		\item {\bf Deterministic:} Simply evaluating all single and double excitations from the initial Slater determinant. Complexity: $\mathcal{O}(N^2 (M-N)^2)$
		\item {\bf Stochastic:} Sampling excitations according to some distribution. Reduces the complexity, but introduces a stochastic uncertainty (and in projector methods, the fermion sign problem!)
		\item {\bf Semistochastic:} Evaluating the largest-magnitude components, and sampling the remaining, smaller components. Reduces complexity relative to the deterministic approach, but with a greatly reduced stochastic uncertainty relative to fully stochastic methods. In projector methods, it also mitigates the bias incurred in taming the fermion sign problem, such as the initiator bias in FCIQMC.
	\end{enumerate}
\end{frame}

\begin{frame}{Semistochastic approach}
	\begin{enumerate}
		\uncover<2->{\item Separate out the sum into a {\bf few large terms} and {\bf many small terms} using some threshold $\epsilon$}
		\uncover<3->{\item Compute the sum of the few large terms deterministically (and quickly)}
		\uncover<4->{\item Importance sample the many small terms}
	\end{enumerate}
	\uncover<5->{
		\begin{eqnarray}
			H\left|D_i\right\rangle &=& \sum_j H_{ji} \\
			&=& \underbrace{\sum_j H_{ji}  \bigg\vert_{|H_{ji}|\ge \epsilon}}_{\substack{ \rm few \; large\;terms:\\\rm sum\; deterministically}}  \quad +\quad \underbrace{\sum_j H_{ji} \bigg\vert_{|H_{ji}|< \epsilon}}_{\substack{\rm many\; small\;terms:\\\rm importance\;sample}}
		\end{eqnarray}
	}
\end{frame}

\section{Algorithm}
\subsection{Deterministic component}
\begin{frame}{Deterministic component}
	\Wider{
		\begin{itemize}
			\item  \textbf{Setup:}
			\begin{itemize}
				\item  For each pair of orbitals $\left\{p,q\right\}$, store a list of %triplets
				$\left\{r,s,\left|H\left(rs\leftarrow pq\right)\right|\right\}$,
				sorted by $\left|H\left(rs\leftarrow pq\right)\right|$ in decreasing order
				\linebreak
				\item Also compute (for sampling algorithm):
				\begin{eqnarray}
				\sum_{rs\in\textrm{remaining}} |H(rs\leftarrow pq)|
				\end{eqnarray}
			\end{itemize}
			{\color{white}  skip line}
			\\
			\uncover<2->{
				\item \textbf{Finding important connected determinants} $D_j$ (for which $\left|H_{ji}\right|>\epsilon$): %for at least one $i\in \mathcal{V}$)
				\\{\color{white}  skip line}
				\\
			}
			\begin{itemize}
				\uncover<3->{
					%\item  \textbf{Generate only those double excitations that exceed $\epsilon$.}
					%\\
					\item For each pair of occupied orbitals $\left\{p,q\right\}$, look up the stored list
					of triplets $\left\{r,s,\left|H\left(rs\leftarrow pq\right)\right|\right\}$ and iterate
					through the list until a triplet is reached for which $\left|H\left(rs\leftarrow pq\right)\right|<\epsilon$
				}
				\\{\color{white}  skip line}
				\\
			\end{itemize}
		\end{itemize}
	}
\end{frame}

\begin{frame}{Deterministic component}
	\begin{center}
		\includegraphics[width=90mm]{heatbath_algo.png}
	\end{center}
\end{frame}

\subsection{Stochastic component}
\begin{frame}{Discrete sampling algorithms}
	\begin{itemize}
		\item \textbf{Alias sampling:}
		\begin{enumerate}
			\item Sample an element with uniform probability
			\item If a low-probability element was selected, it has some probability of `aliasing' to another, high-probability element
		\end{enumerate}
	    \begin{itemize}
	    	\item Setup time: $\mathcal{O}(N)$, Time per sample: $\mathcal{O}(1)$
    	\end{itemize}
		\item \textbf{Cumulative distribution function (CDF) searching:}
		\begin{enumerate}
			\item Sample a real number $r$ uniformly between 0 and 1
			\item Binary-search the CDF for $r$ (i.e., find the smallest index $i$ for which $r<\textrm{CDF}_i$)
		\end{enumerate}	
		\begin{itemize}
			\item Setup time: $\mathcal{O}(N)$, Time per sample: $\mathcal{O}(\log N)$
		\end{itemize}
		\item Usually, Alias sampling is preferred because it has lower sampling complexity, but CDF searching has a unique use case that we will need...
	\end{itemize}
\end{frame}

\begin{frame}{CDF searching's unique use case}
	Suppose we have a stored CDF, and we want to be able to efficiently sample one of the first $n$ elements, where $n$ is not known ahead of time. CDF searching can do this efficiently with a small modification:
	\begin{enumerate}
		\item Sample a real number $r$ uniformly between 0 and $\textrm{CDF}_n$ (Note that $\textrm{CDF}_N=1$ reduces to the original algorithm)
		\item Binary-search the CDF for $r$ (i.e., find the smallest index $i$ for which $r<\textrm{CDF}_i$)
	\end{enumerate}
\end{frame}

\begin{frame}{Importance-sampling excitations}
	\begin{itemize}
	\item Recall that we have already described how to treat the large-magnitude ($|H_{ji}|\ge \epsilon$) excitations deterministically
	\item Now, we want to ``importance-sample'' the remaining small-magnitude ($|H_{ji}|<\epsilon$) excitations, i.e.:
	\begin{eqnarray}
		P(H_{ji}) \begin{cases}
			\propto  f(|H_{ji}|),&\textrm{if $|H_{ji}| < \epsilon$};\\
			=  0, &\textrm{if $|H_{ji}|\ge\epsilon$}. % (because we already treated these deterministically)}.
		\end{cases}
	\end{eqnarray}
	\item Examples of importance-sampling distributions include: \begin{eqnarray}f(|H_{ji}|) = |H_{ji}|,\quad \quad f(|H_{ji}|) = |H_{ji}|^2\end{eqnarray}
	\end{itemize}
\end{frame}

\begin{frame}{Importance-sampling excitations}
	We divide the sampling of an excitation into two stages:
	\begin{enumerate}
		\item Sample an exciting electron pair
			\begin{itemize}
				\item with probability proportional to the sum of remaining (small-magnitude) targets it could excite to
			\end{itemize}
		\item Sample a target orbital pair
		\begin{itemize}
			\item with probability proportional to its excitation magnitude
		\end{itemize}
	\end{enumerate}
\end{frame}

\begin{frame}{Sampling an exciting electron pair}
	\begin{itemize}
		\item During the deterministic step, for each exciting electron pair, we iterate over the sorted excitation magnitudes
		\item As soon as the threshold is reached, we record the sum of remaining excitation magnitudes as that electron pair's relative probability
		\item After doing this for all electron pairs, we set up the Alias sampling data structure in $\mathcal{O}(N^2)$ time
		\item This enables \textbf{importance-sampling an exciting electron pair in $\mathcal{O}(1)$ time}
	\end{itemize}
\end{frame}

\begin{frame}{Sampling a target orbital pair}
	\begin{itemize}
		\item Once an exciting electron pair is selected, we now have to sample a target orbital pair to excite to
		\item Since the deterministic stage has already been completed, we know which target orbital pair $(r,s)$ is the first one that hasn't been treated deterministically
		\item We have a CDF (in reverse order) corresponding to all target orbital pairs, and we need to sample one of the orbital pairs whose index is at least as high as this one
		\item So, we just use CDF searching to \textbf{sample a target orbital pair in $\mathcal{O}(\log M)$ time}
	\end{itemize}
\end{frame}

\subsection{Details and extensions}
\begin{frame}{What about single excitations?}
	\begin{itemize}
		%\small
		\item Unlike double excitations, single excitation matrix element magnitudes depend on the orbital occupancies of the exciting determinant
		\item But we can compute upper bounds to the single excitation magnitudes:
%		\tiny
		\begin{eqnarray}
			\left|H(p\rightarrow r)\right| %&=& \left|f_{pr} + \sum_{q\in \textrm{occ}} g_{pqqr}\right|\\
			\le \left|H(p\rightarrow r)\right|_{\max},%&=&\max\Bigg( \left|f_{pr} + \sum_{q\in [N-1 \textrm{ largest}]} g_{pqqr}\right|,
%			\\&&\quad \quad \quad 
%			\quad \left|f_{pr} + \sum_{q\in [N-1 \textrm{ smallest}]} g_{pqqr}\right|\Bigg),
		\end{eqnarray}
%		%\]
%		\small
%		where the sums in the last line above are over the $N-1$ distinct spin-orbitals $q\notin\{p,r\}$ (of the correct total spin) for which $g_{pqqr}$ is largest or smallest (the values, not the magnitudes), respectively
		where $|H(p\rightarrow r)|_{\max}$ is the largest magnitude the $p\rightarrow r$ excitation can have from any initial determinant
		\item The simplest way to incorporate singles is to sample them with probability $P(|H(p\rightarrow r)|) \propto f(|H(p\rightarrow r)|_{\max})$ and skip them in the deterministic step
	\end{itemize}
\end{frame}

\begin{frame}{Sampling `invalid' excitations}
\begin{itemize}
	\item Sometimes this algorithm will sample `invalid' excitations to already-occupied orbitals
	\item While unbiased, this increases the variance in the samples
	\item We can fix this as follows:
	\begin{enumerate}
		\item If an `invalid' excitation is sampled, discard it and resample until a valid excitation is sampled
		\item Scale the sample probabilities by a constant factor so they remain normalized (can be performed in $\mathcal{O}(N^3)$ time during deterministic step)
	\end{enumerate}
\end{itemize}	
\end{frame}

\section{Applications}
\subsection{Epstein-Nesbet perturbation theory}
\begin{frame}{Epstein-Nesbet perturbation theory}
Given a variational wavefunction $\psi_0=\sum_i c_i \left|D_i\right\rangle$ with energy $E_0$, the Epstein-Nesbet perturbative correction to the energy is give by
\begin{eqnarray}
	\Delta E\left[V\left|\psi_0\right\rangle\right] &=& \left\langle \psi_0 \left| V \frac{1}{E_0 - H_0} V \right|\psi_0\right\rangle\\
	&=& \sum_{\substack{a\in \mathcal{C}(\mathcal{V})\\\notin \mathcal{V}}} \frac{1}{E_0 - E_a} \left(\sum_{ij\in\mathcal{V}} c_j H_{ja} H_{ai} c_i\right),
\end{eqnarray}
so we can now evaluate the $H_{ai}$ components semistochastically using importance sampling.
\end{frame}

\begin{frame}{Semistochastic Epstein-Nesbet Perturbation Theory}
	\begin{enumerate}
		\item Divide $V\left|\psi_0\right\rangle$ into two pieces:
		\begin{eqnarray}
			H\left|\psi_0\right\rangle = \left(V\left|\psi_0\right\rangle\right)_{\ge \epsilon} + \left(V\left|\psi_0\right\rangle\right)_{<\epsilon}.
		\end{eqnarray}
		\item Estimate $\Delta E$ deterministically:
		\begin{eqnarray}
			\Delta E\left[V\left|\psi_0\right\rangle\right] \approx \Delta E\left[\left(V\left|\psi_0\right\rangle\right)_{\ge \epsilon}\right] 
		\end{eqnarray}
		\item Stochastically evaluate the difference between the exact and approximate $\Delta E$
		%\begin{eqnarray}
		%	\Delta E\left[V\left|\psi_0\right\rangle\right] - \Delta E\left[\left(V\left|\psi_0\right\rangle\right)_{\ge \epsilon}\right] .
		%\end{eqnarray}
	\end{enumerate}
\end{frame}

\begin{frame}{Sampling algorithm in Epstein-Nesbet PT}
	How to evaluate the stochastic component?
	\linebreak
	\begin{itemize}
		\item Old approach (SHCI):
		\linebreak
		\begin{itemize}
			\item Sample a batch of determinants $\{D_i\}$ from $\psi_0$, compute $\sum_a H_{ai}c_i$ deterministically for each sampled $D_i$
			\linebreak
			\item Drawbacks:
			\begin{itemize}
				\item No importance sampling of $H$ matrix elements
				\item Memory-limited because requires computing all determinants $\{D_a\}$ for which $H_{ai}\ne 0$
				\item Wastes time on small-magnitude $H_{ai}$ elements
			\end{itemize}
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Sampling algorithm in Epstein-Nesbet PT}
	\begin{itemize}
		\item New approach (Importance sampling):
		\linebreak
		\begin{itemize}
			\item Sample pairs of determinants $\{D_i, D_a\}$ %from $\psi_0$ and $\left(H\left|\psi_0\right\rangle\right)_{<\epsilon}$ respectively
			using importance sampling: \begin{eqnarray} P(D_i, D_a) \propto \left(H_{ai} c_i\right)^2 \end{eqnarray}
			\item Use those samples to evaluate the stochastic component of $\Delta E$,%\left[\left(V\left|\psi_0\right\rangle\right)_{\ge \epsilon}\right]$,
			whose largest-magnitude component is
			\begin{eqnarray}
				\sum_{ai %\substack{ai\\\textrm{ s.t. }\\|H_{ai}c_i|<\epsilon}
				}\frac{ \left(H_{ai}c_i\right)^2}{E_0 - E_a}
			\end{eqnarray}
			\item Advantages:
			\begin{itemize}
				\item Uses importance sampling to greatly reduce the variance!
				\item No time or memory is wasted on deterministically evaluating contributions from small-magnitude $H_{ai}$ elements!
			\end{itemize}
		\end{itemize}
	\end{itemize}
\end{frame}

\subsection{Full CI Quantum Monte Carlo}
\begin{frame}{FCIQMC Overview}
	\begin{itemize}
	\item Power method to project out the Full CI ground state:
	\begin{eqnarray}
		\psi_0 \propto \lim_{n\rightarrow\infty} (1 - \tau H)^n \psi_T
	\end{eqnarray}
	\item When the Hilbert space is too large, we can simulate each iteration of the power method
	\begin{eqnarray}
		\psi^{(t)} = (1 - \tau H)\psi^{(t-1)}
	\end{eqnarray}
	by applying $H$ stochastically (or semistochastically)
	\linebreak
	\item The energy can be estimated using a mixed estimator:
	\begin{eqnarray}
		E_0 = \frac{\left\langle\psi_T\left|H\right|\psi_0\right\rangle}{\left\langle\psi_T\vert \psi_0\right\rangle},
	\end{eqnarray}
	using a precomputed $\psi_T$ (e.g. from Selected CI)	
	\end{itemize}
\end{frame}

\begin{frame}{Semistochastic algorithm in FCIQMC}
	How to perform the semistochastic projection $\psi^{(t)} = (1-\tau H)\psi^{(t-1)}$?
	\begin{itemize}
		\item Old approach (Semistochastic FCIQMC):
		\begin{enumerate}
			\item Choose a fixed set of `important' determinants $\mathcal{D}$ (e.g., using Selected CI) before the run
			\item Deterministically apply the diagonal Hamiltonian matrix elements, and the off-diagonal elements between pairs of important determinants
			\item Importance-sample off-diagonal elements, discard the ones that were already treated deterministically
		\end{enumerate}
	\end{itemize}
\end{frame}

\begin{frame}{Semistochastic algorithm in FCIQMC}
	\begin{itemize}
		\item New approach (Dynamic, importance-sampled semistochastic FCIQMC):
		\linebreak
		\begin{enumerate}
			\item Apply the Hamiltonian using semistochastic importance sampling to each determinant in $\psi^{(t)}$
			\linebreak
		\end{enumerate}
		%\begin{itemize}
			
			\item Advantages:
			\linebreak
			\begin{itemize}
				\item Deterministic/stochastic division is dynamic: it depends on the current $\psi^{(t)}$, which should greatly reduce the stochastic fluctuations and mitigate the fermion sign problem
				\linebreak
				\item Directly samples the off-diagonal $H$ elements that were not treated deterministically, which should greatly reduce the computational time
			\end{itemize}
		%\end{itemize}
	\end{itemize}	
\end{frame}

\end{document}
